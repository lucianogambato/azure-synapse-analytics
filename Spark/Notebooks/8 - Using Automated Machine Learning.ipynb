{
  "metadata": {
    "saveOutput": true,
    "kernelspec": {
      "name": "python3-azureml",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using Automated Machine Learning\n",
        "\n",
        "There are many kinds of machine learning algorithm that you can use to train a model, and sometimes it's not easy to determine the most effective algorithm for your particular data and prediction requirements. Additionally, you can significantly affect the predictive performance of a model by preprocessing the training data, using techniques such as normalization, missing feature imputation, and others. In your quest to find the *best* model for your requirements, you may need to try many combinations of algorithms and preprocessing transformations; which takes a lot of time and compute resources.\n",
        "\n",
        "Azure Machine Learning enables you to automate the comparison of models trained using different algorithms and preprocessing options. You can use the visual interface in [Azure Machine Learning studio](https://ml/azure.com) or the SDK to leverage this capability. he SDK gives you greater control over the settings for the automated machine learning experiment, but the visual interface is easier to use. In this lab, you'll explore automated machine learning using the SDK.\n",
        "\n",
        "## Connect to Your Workspace\n",
        "\n",
        "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
        "\n",
        "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "zipp 3.1.0\nzict 1.0.0\nxlwt 1.2.0\nXlsxWriter 0.9.6\nxlrd 1.0.0\nwrapt 1.11.2\nwidgetsnbextension 2.0.0\nwheel 0.30.0\nWerkzeug 0.16.0\nwebsocket-client 0.57.0\nwcwidth 0.1.7\nvega-datasets 0.7.0\nurllib3 1.25.9\nunicodecsv 0.14.1\ntyping-extensions 3.7.4\ntraitlets 4.3.2\ntqdm 4.46.1\ntornado 6.0.3\ntorch 1.3.0\ntoolz 0.10.0\ntestpath 0.3\nterminado 0.6\ntermcolor 1.1.0\ntensorflow 1.14.0\ntensorflow-estimator 1.14.0\ntensorboard 1.14.0\ntblib 1.4.0\ntables 3.3.0\nsympy 1.0\nstatsmodels 0.10.1\nSQLAlchemy 1.1.9\nspyder 3.1.4\nsortedcontainers 2.1.0\nsortedcollections 0.5.3\nsnowballstemmer 1.2.1\nsmart-open 1.8.4\nsklearn-pandas 1.7.0\nskl2onnx 1.4.9\nsix 1.15.0\nsingledispatch 3.4.0.3\nsimplegeneric 0.8.1\nshap 0.34.0\nsetuptools 41.4.0\nSecretStorage 3.1.2\nseaborn 0.9.0\nscipy 1.1.0\nscikit-learn 0.20.3\nscikit-image 0.15.0\ns3transfer 0.2.1\nruamel.yaml 0.16.10\nruamel.yaml.clib 0.2.0\nrope-py3k 0.9.4.post1\nretrying 1.3.3\nResource 0.2.1\nrequests 2.24.0\nrequests-oauthlib 1.3.0\nQtPy 1.2.1\nqtconsole 4.3.0\nQtAwesome 0.4.4\npyzmq 16.0.2\nPyYAML 5.1.2\nPyWavelets 1.0.3\npytz 2020.1\nPython-EasyConfig 0.1.7\npython-dateutil 2.8.1\npytest 3.0.7\npyspark 2.4.4\npyrsistent 0.15.4\npyparsing 2.4.2\npyOpenSSL 19.1.0\npyodbc 4.0.16\npymssql 2.1.4\npylint 1.6.4\nPyJWT 1.7.1\nPygments 2.2.0\npygal 2.4.0\npyflakes 2.1.1\npycurl 7.43.0\npyct 0.4.6\npycrypto 2.6.1\npycparser 2.20\npycosat 0.6.2\npycodestyle 2.5.0\npyasn1 0.4.8\npyarrow 0.15.1\npy4j 0.10.7\npy 1.4.33\npy-cpuinfo 6.0.0\nptyprocess 0.5.1\npsutil 5.2.2\nprotobuf 3.10.0\nprompt-toolkit 2.0.10\nportalocker 1.7.0\npmdarima 1.1.1\nply 3.10\nplotly 4.1.1\npip 9.0.1\nPillow 6.2.0\npickleshare 0.7.4\npexpect 4.2.1\npep8 1.7.0\npatsy 0.5.1\npathspec 0.8.0\npathlib2 2.2.1\npartd 1.0.0\nparam 1.9.2\npandocfilters 1.4.1\npandas 0.23.4\npackaging 19.2\nopenpyxl 2.4.7\nonnxruntime 0.4.0\nonnxmltools 1.4.1\nonnxconverter-common 1.5.5\nonnx 1.6.0\nolefile 0.44\nodo 0.5.0\noauthlib 3.1.0\nnumpydoc 0.6.0\nnumpy 1.16.2\nnumexpr 2.6.2\nnumba 0.33.0\nnotebookutils 20200608.1\nnotebook 5.0.0\nnose 1.3.7\nnltk 3.2.3\nnimbusml 1.5.0\nnetworkx 2.3\nndg-httpsclient 0.5.1\nnbformat 4.3.0\nnbconvert 5.1.1\nnavigator-updater 0.1.0\nmultipledispatch 0.4.9\nmultimethods 1.0.0\nmsrestazure 0.6.4\nmsrest 0.6.17\nmsgpack 0.6.2\nmsgpack-python 0.4.8\nmsal 1.4.1\nmsal-extensions 0.1.3\nmpmath 0.19\nmore-itertools 7.2.0\nmmlspark 1.0.0.dev1\nmistune 0.7.4\nmissingno 0.4.2\nmccabe 0.6.1\nmatplotlib 3.1.1\nMarkupSafe 1.1.1\nMarkdown 3.1.1\nlxml 3.7.3\nlocket 0.2.0\nllvmlite 0.18.0\nlightgbm 2.2.3\nliac-arff 2.4.0\nlazy-object-proxy 1.2.2\nkiwisolver 1.1.0\nkeras2onnx 1.5.2\nKeras-Preprocessing 1.1.0\nKeras-Applications 1.0.8\njupyter 1.0.0\njupyter-core 4.3.0\njupyter-console 5.1.0\njupyter-client 5.0.1\nJsonSir 0.0.2\njsonschema 3.1.1\njsonpickle 1.4.1\nJsonForm 0.0.2\njson-logging-py 0.2\njoblib 0.14.1\njmespath 0.10.0\nJinja2 2.10.3\njeepney 0.4.3\njedi 0.10.2\njdcal 1.3\nitsdangerous 0.24\nisort 4.2.5\nisodate 0.6.0\nipywidgets 6.0.0\nipython 7.8.0\nipython-genutils 0.2.0\nipykernel 4.6.1\ninterpret-core 0.1.21\ninterpret-community 0.10.2\nimportlib-metadata 1.7.0\nimagesize 0.7.1\nimageio 2.6.1\nidna 2.10\nhyperspace 0.0.1\nhtml5lib 0.999\nHeapDict 1.0.1\nh5py 2.10.0\ngunicorn 19.9.0\ngrpcio 1.24.1\ngreenlet 0.4.12\ngoogle-pasta 0.1.7\ngevent 1.2.1\ngensim 3.8.1\ngast 0.3.2\nfusepy 3.0.1\nfsspec 0.5.2\nFlask 1.0.3\nFlask-Cors 3.0.2\nflake8 3.7.9\nfire 0.2.1\nfastcache 1.0.2\net-xmlfile 1.0.1\nentrypoints 0.3\ndotnetcore2 2.1.14\ndocutils 0.15.2\ndocker 4.2.1\ndistro 1.5.0\ndistributed 1.16.3\ndill 0.3.1.1\ndecorator 4.4.0\ndatashape 0.5.4\ndask 0.14.3\ncytoolz 0.8.2\nCython 0.29.13\ncycler 0.10.0\ncryptography 2.9.2\ncontextlib2 0.6.0.post1\nconfigparser 3.7.4\ncolorama 0.3.9\nclyent 1.2.2\ncloudpickle 1.4.1\nclick 6.7\nchart-studio 1.0.0\nchardet 3.0.4\ncffi 1.14.0\ncertifi 2020.6.20\nBottleneck 1.2.1\nbotocore 1.12.247\nboto3 1.9.247\nboto 2.49.0\nbokeh 1.3.4\nbleach 1.5.0\nblaze 0.10.1\nbitarray 0.8.1\nbeautifulsoup4 4.6.0\nbackports.weakref 1.0.post1\nbackports.tempfile 1.0\nbackports.shutil-get-terminal-size 1.0.0\nbackcall 0.2.0\nBabel 2.4.0\nazureml-train 1.8.0\nazureml-train-restclients-hyperdrive 1.8.0\nazureml-train-core 1.8.0\nazureml-train-automl 1.6.0\nazureml-train-automl-runtime 1.6.0\nazureml-train-automl-client 1.8.0\nazureml-telemetry 1.8.0\nazureml-sdk 1.8.0\nazureml-pipeline 1.8.0\nazureml-pipeline-steps 1.8.0\nazureml-pipeline-core 1.8.0\nazureml-opendatasets 1.6.0\nazureml-model-management-sdk 1.0.1b6.post1\nazureml-interpret 1.6.0\nazureml-explain-model 1.6.0\nazureml-defaults 1.6.0\nazureml-dataprep 1.8.3\nazureml-dataprep-native 14.2.1\nazureml-core 1.8.0.post1\nazureml-automl-runtime 1.6.0.post1\nazureml-automl-core 1.8.0\nazure-storage-common 2.1.0\nazure-storage-blob 2.1.0\nazure-mgmt-storage 11.1.0\nazure-mgmt-resource 10.0.0\nazure-mgmt-network 10.2.0\nazure-mgmt-keyvault 2.2.0\nazure-mgmt-containerregistry 2.8.0\nazure-mgmt-authorization 0.60.0\nazure-identity 1.2.0\nazure-graphrbac 0.61.1\nazure-core 1.6.0\nazure-common 1.1.25\nattrs 19.2.0\nastropy 1.3.2\nastroid 1.4.9\nastor 0.8.0\nasn1crypto 1.0.1\napplicationinsights 0.11.9\naltair 3.2.0\nalabaster 0.7.10\nadal 1.2.4\nabsl-py 0.8.1\nSphinx 1.5.6"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "outputCollapsed": true
      },
      "source": [
        "import pip \n",
        "for i in pip.get_installed_distributions(local_only=True):\n",
        "    print(i)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "Ready to use Azure ML 1.8.0 to work with dp100-workspace"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.get(name='dp100-workspace',\n",
        " subscription_id='98214768-053e-4f2d-bbd7-5db5549e5c42',\n",
        " resource_group='dp100-rg')\n",
        "\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Data for Automated Machine Learning\n",
        "\n",
        "You don't need to create a training script for automated machine learning, but you do need to load the training data. In this case, you'll create a dataset containing details of diabetes patients (just as you did in previous labs), and then split this into two datasets: one for training, and another for model validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Dataset already registered.\nData ready!"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')\n",
        "\n",
        "\n",
        "# Split the dataset into training and validation subsets\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "train_ds, test_ds = diabetes_ds.random_split(percentage=0.7, seed=123)\n",
        "print(\"Data ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare a Compute Target\n",
        "\n",
        "One of the benefits of cloud compute is that it scales on-demand, enabling you to provision enough compute resources to process multiple runs of an experiment in parallel.\n",
        "\n",
        "You'll use the Azure Machine Learning compute cluster you created in an earlier lab (if it doesn't exist, it will be created).\n",
        "\n",
        "> **Important**: Change *your-compute-cluster* to the name of your compute cluster in the code below before running it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "Found existing cluster, use it.\nSucceeded\nAmlCompute wait for completion finished\n\nMinimum number of nodes requested have been provisioned"
          },
          "metadata": {}
        }
      ],
      "metadata": {},
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"aml-cluster\"\n",
        "\n",
        "try:\n",
        "    # Get the cluster if it exists\n",
        "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If not, create it\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS2_V2', max_nodes=2)\n",
        "    training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "training_cluster.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configure Automated Machine Learning\n",
        "\n",
        "Now you're ready to configure the automated machine learning experiment. To do this, you'll need a run configuration that includes the required packages for the experiment environment, and a set of configuration settings that specifies how many combinations to try, which metric to use when evaluating models, and so on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "automl_config = AutoMLConfig(name='Automated ML Experiment',\n",
        "                             task='classification',\n",
        "                             compute_target=training_cluster,\n",
        "                             training_data = train_ds,\n",
        "                             validation_data = test_ds,\n",
        "                             label_column_name='Diabetic',\n",
        "                             iterations=4,\n",
        "                             primary_metric = 'AUC_weighted',\n",
        "                             max_concurrent_iterations=4,\n",
        "                             featurization='auto'\n",
        "                             )\n",
        "\n",
        "print(\"Ready for Auto ML run.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run an Automated Machine Learning Experiment\n",
        "\n",
        "OK, you're ready to go. Let's run the automated machine learning experiment.\n",
        "\n",
        "> **Note**: In this lab, you'll run the automated machine learning experiment with a maximum of 6 iterations to save time. In reality, you might want to try many more iterations using a training cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "scrolled": false
      },
      "source": [
        "from azureml.core.experiment import Experiment\n",
        "## from azureml.widgets import RunDetails\n",
        "\n",
        "print('Submitting Auto ML experiment...')\n",
        "automl_experiment = Experiment(ws, 'diabetes_automl')\n",
        "automl_run = automl_experiment.submit(automl_config)\n",
        "##RunDetails(automl_run).show()\n",
        "automl_run.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Determine the Best Performing Model\n",
        "\n",
        "When the experiment has completed, view the output in the widget, and click the run that produced the best result to see its details.\n",
        "Then click the link to view the experiment details in the Azure portal and view the overall experiment details before viewing the details for the individual run that produced the best result. There's lots of information here about the performance of the model generated.\n",
        "\n",
        "Let's get the best run and the model that it produced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "best_run, fitted_model = automl_run.get_output()\n",
        "print(best_run)\n",
        "print(fitted_model)\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "for metric_name in best_run_metrics:\n",
        "    metric = best_run_metrics[metric_name]\n",
        "    print(metric_name, metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Automated machine learning includes the option to try preprocessing the data, which is accomplished through the use of [Scikit-Learn transformation pipelines](https://scikit-learn.org/stable/modules/compose.html#combining-estimators) (not to be confused with Azure Machine Learning pipelines!). These produce models that include steps to transform the data before inferencing. You can view the steps in a model like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "for step in fitted_model.named_steps:\n",
        "    print(step)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, having found the best performing model, you can register it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {},
      "source": [
        "from azureml.core import Model\n",
        "\n",
        "# Register model\n",
        "best_run.register_model(model_path='outputs/model.pkl', model_name='diabetes_model_automl',\n",
        "                        tags={'Training context':'Auto ML'},\n",
        "                        properties={'AUC': best_run_metrics['AUC_weighted'], 'Accuracy': best_run_metrics['accuracy']})\n",
        "\n",
        "# List registered models\n",
        "for model in Model.list(ws):\n",
        "    print(model.name, 'version:', model.version)\n",
        "    for tag_name in model.tags:\n",
        "        tag = model.tags[tag_name]\n",
        "        print ('\\t',tag_name, ':', tag)\n",
        "    for prop_name in model.properties:\n",
        "        prop = model.properties[prop_name]\n",
        "        print ('\\t',prop_name, ':', prop)\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **More Information**: For more information Automated Machine Learning, see the [Azure ML documentation](https://docs.microsoft.com/azure/machine-learning/how-to-configure-auto-train)."
      ]
    }
  ]
}